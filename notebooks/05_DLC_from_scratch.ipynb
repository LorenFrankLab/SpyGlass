{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93a1550-8a67-4346-a4bf-e5a136f3d903",
   "metadata": {},
   "source": [
    "## Position using DeepLabCut from Scratch\n",
    "\n",
    "**Note: make a copy of this notebook and run the copy to avoid git conflicts in the future**\n",
    "\n",
    "This is a tutorial on how to extract position via DeepLabCut (DLC) using the Spyglass pipeline used in Loren Frank's lab, UCSF. It will walk through creating your DLC project, extracting and labeling frames, training your model, executing pose estimation on a novel behavioral video, processing the pose estimation output to extract a centroid and orientation, and inserting the resulting information into the `PositionOutput` table.<br>\n",
    "-> This tutorial assumes you've completed [tutorial 0](0_intro.ipynb)<br>\n",
    "**Note 2: Make sure you are running this within the spyglass-position Conda environment (instructions for install are in the environment_position.yml)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f567531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PosixPath, PurePath\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynwb\n",
    "import datajoint as dj\n",
    "import spyglass.common as sgc\n",
    "import spyglass.position.v1 as sgp\n",
    "from spyglass.position import PositionOutput"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8b531f7",
   "metadata": {},
   "source": [
    "#### Here is a schematic showing the tables used in this notebook.<br>\n",
    "![dlc_scratch.png|2000x900](./../notebook-images/dlc_scratch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67d88c-c90e-467b-ae2e-672c49a12f95",
   "metadata": {},
   "source": [
    "### Table of Contents<a id='TableOfContents'></a>\n",
    "[`DLCProject`](#DLCProject1)<br>\n",
    "[`DLCModelTraining`](#DLCModelTraining1)<br>\n",
    "[`DLCModel`](#DLCModel1)<br>\n",
    "[`DLCPoseEstimation`](#DLCPoseEstimation1)<br>\n",
    "[`DLCSmoothInterp`](#DLCSmoothInterp1)<br>\n",
    "[`DLCCentroid`](#DLCCentroid1)<br>\n",
    "[`DLCOrientation`](#DLCOrientation1)<br>\n",
    "[`DLCPosV1`](#DLCPosV1-1)<br>\n",
    "[`DLCPosVideo`](#DLCPosVideo1)<br>\n",
    "[`PositionOutput`](#PositionOutput1)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6221a3-17e5-45c0-aa40-2fd664b02219",
   "metadata": {},
   "source": [
    "#### [DLCProject](#TableOfContents) <a id=\"DLCProject1\"></a>\n",
    "__You can click on any header to return to the Table of Contents__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aed0e1-3af7-4499-bae8-96a64e81041e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The cells within the <code>DLCProject</code> step need to be performed in a local Jupyter notebook to allow for use of the frame labeling GUI.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96637cb9-519d-41e1-8bfd-69f68dc66b36",
   "metadata": {},
   "source": [
    "Let us begin with visualizing the contents of the BodyPart table. This table will store standard names of body parts used within DLC models throughout the lab with a concise description.<br>\n",
    "><div class=\"alert alert-block alert-warning\">Please do not add to this table unless necessary.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f829f-9877-48ae-89d1-f876af2b8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.BodyPart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a15e2-f087-4bd2-9d4a-ea2ac4becd80",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "If the bodyparts you plan to use in your model are not yet in the table, here is code to add bodyparts:\n",
    "</div>\n",
    "\n",
    ">```python\n",
    "sgp.BodyPart.insert([{'bodypart': 'bodypart_1', 'bodypart_description': 'concise description of bodypart'},\n",
    "                     {'bodypart': 'bodypart_2', 'bodypart_description': 'concise description of bodypart'},],\n",
    "                    skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe7c06-30c9-43e1-9e9a-029a70b0d4dd",
   "metadata": {},
   "source": [
    "Next we want to construct a list of videos from which we will extract frames to train the model.<br>The list can either contain dictionaries identifying behavioral videos for NWB files that have already been added to Spyglass, or absolute file paths to the videos you want to use.<br>For this tutorial, we'll use two videos for which we already have frames labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = [\n",
    "    {\"nwb_file_name\": \"J1620210529_.nwb\", \"epoch\": 2},\n",
    "    {\"nwb_file_name\": \"peanut20201103_.nwb\", \"epoch\": 4},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c023b0-d00d-40b0-9a37-d0d3e4a4ae2a",
   "metadata": {},
   "source": [
    "Before creating our project, we need to define a few variables.\n",
    ">First, we want to set a team name to one that exists in the `LabTeam` table to ensure proper permission are set.<br>In this case we'll use \"LorenLab\", as all Frank Lab members are a part of this team.<br>\n",
    "We also need to define a `project_name`, which should be a unique identifier for this project. For the tutorial we'll set it as __\"tutorial_scratch_yourinitials\"__<br>Next, we need to define a list of `bodyparts` for which we want to extract position. The pre-labeled frames we're using include the bodyparts listed below, but please modify as needed for your own project.<br>We also want to define how many frames we want to extract and eventually label from each video we're using. I will typically use 200 `frames_per_video`, but we'll keep it to 100 for efficiency's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"LorenLab\"\n",
    "project_name = \"tutorial_scratch_DG\"\n",
    "frames_per_video = 100\n",
    "bodyparts = [\"redLED_C\", \"greenLED\", \"redLED_L\", \"redLED_R\", \"tailBase\"]\n",
    "project_key = sgp.DLCProject.insert_new_project(\n",
    "    project_name=project_name,\n",
    "    bodyparts=bodyparts,\n",
    "    lab_team=team_name,\n",
    "    frames_per_video=frames_per_video,\n",
    "    video_list=video_list,\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d83452-48eb-4669-89eb-a6beb1f2d051",
   "metadata": {},
   "source": [
    "Now that we've intialized our project we'll need to extract and label frames.<br>While this has already been done for this tutorial, here are the commands in order to pull up the DLC GUI to perform these actions:\n",
    ">```python\n",
    "sgp.DLCProject().run_extract_frames(project_key)\n",
    "sgp.DLCProject().run_label_frames(project_key)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df257015",
   "metadata": {},
   "source": [
    "Typically, in order to use pre-labeled frames to your project you'll need to change the values in the labeled-data files. You can do that using the `import_labeled_frames` method. \n",
    "<blockquote>This function expects the `project_key` from your new project<br>The absolute path to the project you want to import the labeled frames from<br>The filename (without file extension) of the videos from which you want the frames.\n",
    "</blockquote>Here we'll use the path to a pre-existing project from tutorial 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a9526-fcd1-417b-b368-00d17e0284e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCProject.import_labeled_frames(\n",
    "    project_key.copy(),\n",
    "    import_project_path=\"/nimbus/deeplabcut/projects/tutorial_model-LorenLab-2022-07-15/\",\n",
    "    video_filenames=[\"20201103_peanut_04_r2\", \"20210529_J16_02_r1\"],\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12dd229-2f8b-455a-a7b1-a20916cefed9",
   "metadata": {},
   "source": [
    "Now we can check the `DLCProject.File` part table and see all of our training files and videos there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f3fa6-cce9-4d4a-a252-3424313c6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCProject.File & project_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e3eab-60c7-4a3c-bc8f-fd4e8dcf52a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>This step and beyond should be run on a GPU-enabled machine.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48ecf0",
   "metadata": {},
   "source": [
    "#### [DLCModelTraining](#ToC)<a id='DLCModelTraining1'></a> \n",
    "Please make sure you're running this notebook on a GPU-enabled machine.<br>\n",
    "Now that we've imported existing frames, we can get ready to train our model.<br>\n",
    "First, we'll need to define a set of parameters for `DLCModelTrainingParams`, which will get used by DeepLabCut during training<br>\n",
    "Let's start with `gputouse`<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<code>gputouse</code> determines which GPU core to use for pose estimation. Run the cell below to determine which core has space and set the <code>gputouse</code> variable accordingly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.dlc_utils.get_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca035a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Set GPU core here</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "gputouse = 3  ## 1-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b047686",
   "metadata": {},
   "source": [
    "Now let's define the rest of our parameters and insert the entry.<br>\n",
    "(If you want to see all possible parameters that you can pass, checkout the line below):\n",
    ">```python\n",
    "sgp.DLCModelTrainingParams.get_accepted_params()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params_name = \"tutorial_DG\"\n",
    "sgp.DLCModelTrainingParams.insert_new_params(\n",
    "    paramset_name=training_params_name,\n",
    "    params={\n",
    "        \"trainingsetindex\": 0,\n",
    "        \"shuffle\": 1,\n",
    "        \"gputouse\": gputouse,\n",
    "        \"net_type\": \"resnet_50\",\n",
    "        \"augmenter_type\": \"imgaug\",\n",
    "    },\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cc709",
   "metadata": {},
   "source": [
    "Next we'll modify the `project_key` from above to include the necessary entries for `DLCModelTraining`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"config_path\" in project_key:\n",
    "    del project_key[\"config_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7ddaa",
   "metadata": {},
   "source": [
    "And here we can insert an entry into `DLCModelTrainingSelection` and populate `DLCModelTraining` with that entry, which will run training for us.<br>\n",
    "**Note**: You can stop training at any point using `I + I` or interrupt the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d2f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgp.DLCModelTrainingSelection().insert1(\n",
    "    {\n",
    "        **project_key,\n",
    "        \"dlc_training_params_name\": training_params_name,\n",
    "        \"training_id\": 0,\n",
    "        \"model_prefix\": \"\",\n",
    "    }\n",
    ")\n",
    "model_training_key = (\n",
    "    sgp.DLCModelTrainingSelection\n",
    "    & {\n",
    "        **project_key,\n",
    "        \"dlc_training_params_name\": training_params_name,\n",
    "    }\n",
    ").fetch1(\"KEY\")\n",
    "sgp.DLCModelTraining.populate(model_training_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da004b3e",
   "metadata": {},
   "source": [
    "Here we'll make sure that the entry made it into the table properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5306fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgp.DLCModelTraining() & model_training_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b7687",
   "metadata": {},
   "source": [
    "Populating `DLCModelTraining` automatically inserts the entry into `DLCModelSource`.  `DLCModelSource` is a table that is used to switch between the models we train using Spyglass and pre-existing projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSource() & model_training_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb8969",
   "metadata": {},
   "source": [
    "Notice the `source` field in the table above. It will only accept _\"FromImport\"_ or _\"FromUpstream\"_ as entries. Let's checkout the `FromUpstream` part table attached to `DLCModelSource` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSource.FromUpstream() & model_training_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9b2c6",
   "metadata": {},
   "source": [
    "#### [DLCModel](#TableOfContents) <a id='DLCModel1'></a>\n",
    "Next we'll get ready to populate the `DLCModel` table, which holds all the relevant information for both pre-trained models and models trained within Spyglass.<br>First we'll need to determine a set of parameters for our model to select the correct model file.<br>We can visualize a default set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb663861",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelParams.get_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45a6ed",
   "metadata": {},
   "source": [
    "> Here is the syntax to add your own parameter set:\n",
    ">```python\n",
    "dlc_model_params_name = \"make_this_yours\"\n",
    "params = {\n",
    "            \"params\": {},\n",
    "            \"shuffle\": 1,\n",
    "            \"trainingsetindex\": 0,\n",
    "            \"model_prefix\": \"\",\n",
    "        }\n",
    "sgp.DLCModelParams.insert1({\"dlc_model_params_name\": dlc_model_params_name, \"params\": params}, skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce9696",
   "metadata": {},
   "source": [
    "Now that we've defined a set of parameters and inserted into `DLCModelParams`, we can insert an entry into `DLCModelSelection` and populate `DLCModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa23fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_key = (sgp.DLCModelSource & model_training_key).fetch1(\"KEY\")\n",
    "sgp.DLCModelSelection().insert1({\n",
    "    **temp_model_key,\n",
    "    \"dlc_model_params_name\": \"default\"},\n",
    "    skip_duplicates=True)\n",
    "model_key = (sgp.DLCModelSelection & ).fetch1(\"KEY\")\n",
    "sgp.DLCModel.populate(model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1b839",
   "metadata": {},
   "source": [
    "Again, let's make sure that everything looks correct in `DLCModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModel() & model_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce4ee4",
   "metadata": {},
   "source": [
    "#### [DLCPoseEstimation](#TableOfContents) <a id='DLCPoseEstimation1'></a>\n",
    "\n",
    "Alright, now that we've trained model and populated the `DLCModel` table, we're ready to set-up Pose Estimation on a behavioral video of your choice.<br>For this tutorial, you can choose to use an epoch of your choice, we can also use the one specified below. If you'd like to use your own video, just specify the `nwb_file_name` and `epoch` number and make sure it's in the `VideoFile` table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a8dab-7caf-4389-8494-9158d2ec5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwb_file_name = \"J1620210604_.nwb\"\n",
    "epoch = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfe757-cee8-435a-b902-77b1e6dc1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgc.VideoFile() & {\"nwb_file_name\": nwb_file_name, \"epoch\": epoch}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26a081-859d-4dff-bb58-84cec2ff4b3f",
   "metadata": {},
   "source": [
    "To set up pose estimation, we need to make sure a few things are in order. Using `insert_estimation_task` will take care of these steps for us!<br>Briefly, it will convert out video to be in .mp4 format (DLC struggles with .h264) and determine the directory in which we'll store the pose estimation results.<br>\n",
    ">**`task_mode`** determines whether or not populating `DLCPoseEstimation` runs a new pose estimation, or loads an existing. Use _'trigger'_ unless you've already run this specific pose estimation.<br>**`video_file_num`** will be 0 in almost all cases.<br>__`gputouse`__ has already been set above during the training step. It may be a good idea to make sure that core is still free before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5644f-febc-49d7-a60d-6991798c20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_estimation_key = sgp.DLCPoseEstimationSelection.insert_estimation_task(\n",
    "    {\n",
    "        \"nwb_file_name\": nwb_file_name,\n",
    "        \"epoch\": epoch,\n",
    "        \"video_file_num\": 0,\n",
    "        **model_key,\n",
    "    },\n",
    "    task_mode=\"trigger\",\n",
    "    params={\"gputouse\": gputouse, \"videotype\": \"mp4\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb2a26-fae1-41ca-828f-cc6c73ebd24e",
   "metadata": {},
   "source": [
    "And now we populate `DLCPoseEstimation`! This might take a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f28ecc-d3a4-40f9-a1fb-afb4bdd04497",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPoseEstimation().populate(pose_estimation_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88757488-cfa4-4e7c-b965-7dacac43810a",
   "metadata": {},
   "source": [
    "Let's visualize the output from Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd4f3b-7bf4-41b7-be5f-820fe3ee9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCPoseEstimation() & pose_estimation_key).fetch_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f45ab3-9344-4975-b5ff-f80a5727cdac",
   "metadata": {},
   "source": [
    "#### [DLCSmoothInterp](#TableOfContents) <a id='DLCSmoothInterp1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd5dbe-097a-4138-a234-da78a5902684",
   "metadata": {},
   "source": [
    "Now that we've completed pose estimation, it's time to identify NaNs and optionally interpolate over low likelihood periods and smooth the resulting positions.<br>First we need to define some parameters for smoothing and interpolation. We can see the default parameter set below.<br>__Note__: it is recommended to use the `just_nan` parameters here and save interpolation and smoothing for the centroid step as this provides for a better end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e44a34-8d6d-4206-b02a-9ca38a68f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default parameter set to interpolate and smooth over each LED individually\n",
    "print(sgp.DLCSmoothInterpParams.get_default())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The just_nan parameter set that identifies NaN indices and leaves smoothing and interpolation to the centroid step\n",
    "print(sgp.DLCSmoothInterpParams.get_nan_params())\n",
    "si_params_name = \"just_nan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245c9e5-e8f6-4c6f-b9e1-d71ab3e06d59",
   "metadata": {},
   "source": [
    "> If you'd like to change any of these parameters, here is the syntax to do that\n",
    ">```python\n",
    "si_params_name = 'your_unique_param_name'\n",
    "params = {\n",
    "    \"smoothing_params\": {\n",
    "        \"smoothing_duration\": 0.##,\n",
    "        \"smooth_method\": \"moving_avg\",\n",
    "    },\n",
    "    \"interp_params\": {\n",
    "        \"likelihood_thresh\": 0.##,\n",
    "    },\n",
    "    \"max_plausible_speed\": ###,\n",
    "    \"speed_smoothing_std_dev\": 0.###,\n",
    "}\n",
    "sgp.DLCSmoothInterpParams().insert1(\n",
    "    {\n",
    "        'dlc_si_params_name': si_params_name,\n",
    "        \"params\": params,\n",
    "    },\n",
    "    skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139036e-ce7e-41ec-be78-aa15a4b0b795",
   "metadata": {},
   "source": [
    "Here we'll create a dictionary with the correct set of keys for the `DLCSmoothInterpSelection` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec730b91-a974-4f54-9d55-35f52e08487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "si_key = pose_estimation_key.copy()\n",
    "fields = list(sgp.DLCSmoothInterpSelection.fetch().dtype.fields.keys())\n",
    "si_key = {key: val for key, val in si_key.items() if key in fields}\n",
    "si_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a47a6de-51ff-4980-b105-42a75ef7f7a3",
   "metadata": {},
   "source": [
    "And now we can insert all of the bodyparts we want to process into `DLCSmoothInterpSelection`<br>\n",
    "First lets visualize the bodyparts we have available to us.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fcad0-e211-4bd7-82b1-d69bec0eb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sgp.DLCPoseEstimation.BodyPart & pose_estimation_key).fetch(\"bodypart\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e3ad2-1960-43cd-a223-784c08211013",
   "metadata": {},
   "source": [
    "We can use `insert1` to insert a single bodypart, but would suggest using `insert` to insert a list of keys with different bodyparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70621afe-a144-47f2-9d70-212fbcd85aba",
   "metadata": {},
   "source": [
    ">_Syntax to insert a single bodypart_\n",
    ">```python\n",
    "sgp.DLCSmoothInterpSelection.insert1(\n",
    "    {\n",
    "        **si_key,\n",
    "        'bodypart': 'greenLED',\n",
    "        'dlc_si_params_name': si_params_name,\n",
    "    },\n",
    "    skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f73cd-2534-40a2-86e6-948ccd902812",
   "metadata": {},
   "source": [
    "Lets set a list of bodyparts we want to insert and then insert them into `DLCSmoothInterpSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e826d-38ef-4219-8d52-5353c6b4b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts = [\"greenLED\", \"redLED_C\"]\n",
    "sgp.DLCSmoothInterpSelection.insert(\n",
    "    [\n",
    "        {\n",
    "            **si_key,\n",
    "            \"bodypart\": bodypart,\n",
    "            \"dlc_si_params_name\": si_params_name,\n",
    "        }\n",
    "        for bodypart in bodyparts\n",
    "    ],\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca5640-3e9a-42b7-bc61-7f3e1a219619",
   "metadata": {},
   "source": [
    "And to make sure that all of the bodyparts we want made it into the the selection table, we can visualize the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b347b29-1583-4fbc-9b35-8e062b611d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterpSelection() & si_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f0d26-3879-4f50-a076-e60685028083",
   "metadata": {},
   "source": [
    "Now we can populate `DLCSmoothInterp`, which will perform smoothing and interpolation on all of the bodyparts we specified.<br>We can limit the populate using `si_key` since it is bodypart agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf16c32-0f5e-4cd2-b814-56745e836599",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterp().populate(si_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3af0a2-16cc-43dc-af9c-0ec606cfe1e1",
   "metadata": {},
   "source": [
    "And let's visualize the resulting position data using a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced96b05-e6dc-4771-bfb8-bcbddfb8e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sgp.DLCSmoothInterp() & {**si_key, \"bodypart\": bodyparts[0]}\n",
    ").fetch1_dataframe().plot.scatter(x=\"x\", y=\"y\", s=1, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838e4c4-8ff9-4b73-aee5-00eb91ea899f",
   "metadata": {},
   "source": [
    "#### [DLCSmoothInterpCohort](#TableOfContents) <a id='DLCSmoothInterpCohort1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3d882-2c24-46ca-bfcc-72f21712e47b",
   "metadata": {},
   "source": [
    "Now that we've smoothed and interpolated our position data for each bodypart, we need to form a set of bodyparts from which we want to derive a centroid and orientation (or potentially a second set for orientation). This is the goal of the `DLCSmoothInterpCohort` table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017fd46-2bb9-4349-981b-f9789ffec338",
   "metadata": {},
   "source": [
    "First, let's make a key that represents the 'cohort' we want to form.\n",
    "> We'll set the `dlc_si_cohort_selection_name` to a concise name<br>We'll also form a dictionary with the bodypart name as the key and the smoothing/interpolation parameter name used for that bodypart as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb1af9-20cf-46d9-a518-a7f551334bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_key = si_key.copy()\n",
    "if \"bodypart\" in cohort_key:\n",
    "    del cohort_key[\"bodypart\"]\n",
    "if \"dlc_si_params_name\" in cohort_key:\n",
    "    del cohort_key[\"dlc_si_params_name\"]\n",
    "cohort_key[\"dlc_si_cohort_selection_name\"] = \"green_red_led\"\n",
    "cohort_key[\"bodyparts_params_dict\"] = {\n",
    "    \"greenLED\": si_params_name,\n",
    "    \"redLED_C\": si_params_name,\n",
    "}\n",
    "print(cohort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6a327-d4b0-4de1-a2c6-10a0443a3f96",
   "metadata": {},
   "source": [
    "Here we'll insert the cohort into the `DLCSmoothInterpCohortSelection` table<br>..and populate `DLCSmoothInterpCohort`, which collates the separately smoothed and interpolated bodyparts into a single entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f55c1-3c7b-4cf9-bdd7-98743810c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterpCohortSelection().insert1(cohort_key, skip_duplicates=True)\n",
    "sgp.DLCSmoothInterpCohort.populate(cohort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7d361-47c5-4748-ac59-f51b897f7fe6",
   "metadata": {},
   "source": [
    "And of course, let's make sure that the table populated correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7672b63-6dfc-46db-b8df-95c1e6730b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterpCohort.BodyPart() & cohort_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871bdca-2278-43ec-a70c-52257ad26170",
   "metadata": {},
   "source": [
    "#### [DLCCentroid](#TableOfContents) <a id='DLCCentroid1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc37edb-fdd3-4a05-8cd5-91f3c5f7cbbb",
   "metadata": {},
   "source": [
    "We now have a cohort of smoothed and interpolated bodyparts from which to determine a centroid!<br>To start, we'll need a set of parameters to use for determining the centroid. For this tutorial, we can use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31c8db-0396-475a-af71-ae38433d2b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the default set\n",
    "print(sgp.DLCCentroidParams.get_default())\n",
    "centroid_params_name = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852948f7-e743-4319-be6b-265dadfca713",
   "metadata": {},
   "source": [
    ">Here is the syntax to add your own parameters:\n",
    ">```python\n",
    "centroid_params = {\n",
    "    'centroid_method': 'two_pt_centroid',\n",
    "    'points' : {\n",
    "        'point1': 'greenLED',\n",
    "        'point2': 'redLED_C',},\n",
    "    'speed_smoothing_std_dev': 0.100,\n",
    "}\n",
    "centroid_params_name = 'your_unique_param_name'\n",
    "sgp.DLCCentroidParams.insert1({'dlc_centroid_params_name': centroid_params_name,\n",
    "                                'params': centroid_params},\n",
    "                                skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad4e53-43dd-4e05-84c4-7d4504766746",
   "metadata": {},
   "source": [
    "And now let's make a key to insert into `DLCCentroidSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac17cb-4bb3-47b2-b1b9-1c4b37797591",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_key = cohort_key.copy()\n",
    "fields = list(sgp.DLCCentroidSelection.fetch().dtype.fields.keys())\n",
    "centroid_key = {key: val for key, val in centroid_key.items() if key in fields}\n",
    "centroid_key[\"dlc_centroid_params_name\"] = centroid_params_name\n",
    "print(centroid_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674c0d3-d3fd-4cd9-a843-260c442c2d23",
   "metadata": {},
   "source": [
    "Let's insert it into `DLCCentroidSelection` and then populate `DLCCentroid` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fccef4-2fef-4f74-b7a4-8564328b14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCCentroidSelection.insert1(centroid_key, skip_duplicates=True)\n",
    "sgp.DLCCentroid.populate(centroid_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49c5ad-909f-4f1a-a156-f8f8a84fb78a",
   "metadata": {},
   "source": [
    "Here we can visualize the resulting centroid position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7e447-fa6f-4f06-9ec9-4b9838b7255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCCentroid() & centroid_key).fetch1_dataframe().plot.scatter(\n",
    "    x=\"position_x\",\n",
    "    y=\"position_y\",\n",
    "    c=\"speed\",\n",
    "    colormap=\"viridis\",\n",
    "    alpha=0.5,\n",
    "    s=0.5,\n",
    "    figsize=(10, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb513a9d-5250-404c-8887-639f785516c7",
   "metadata": {},
   "source": [
    "#### [DLCOrientation](#TableOfContents) <a id='DLCOrientation1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509076f0-f0b8-4fd0-8884-32c48ca4a125",
   "metadata": {},
   "source": [
    "We'll now go through a similar process to identify the orientation!<br>To start, we'll need a set of parameters to use for determining the orientation. For this tutorial, we can use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf244b3-7295-48ed-90ea-cf878e85e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sgp.DLCOrientationParams.get_default())\n",
    "dlc_orientation_params_name = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec170be-7a7a-4a20-986c-d055aee1a08b",
   "metadata": {},
   "source": [
    "Here we'll prune the `cohort_key` we used above and add our `dlc_orientation_params_name` to make it suitable for `DLCOrientationSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4a6cf-472e-43e3-90aa-f7ff7fb9dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = list(sgp.DLCOrientationSelection.fetch().dtype.fields.keys())\n",
    "orient_key = {key: val for key, val in cohort_key.items() if key in fields}\n",
    "orient_key[\"dlc_orientation_params_name\"] = dlc_orientation_params_name\n",
    "print(orient_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9406d2de-9b71-4591-82f6-ed53f2d4f220",
   "metadata": {},
   "source": [
    "And now let's insert into `DLCOrientationSelection` and populate `DLCOrientation` to determine the orientation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d23302-02e3-427a-ac35-2f648e3ae674",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCOrientationSelection().insert1(orient_key, skip_duplicates=True)\n",
    "sgp.DLCOrientation().populate(orient_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62da0-0cc5-4ffb-b2df-7b68c3f6e268",
   "metadata": {},
   "source": [
    "We can fetch the output of `DLCOrientation` as a dataframe to make sure everything looks appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eba7f4-0b32-486a-894a-c97404c74d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCOrientation() & orient_key).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75aeaf-018a-46ed-83a8-6603ae100791",
   "metadata": {},
   "source": [
    "#### [DLCPosV1](#TableOfContents) <a id='DLCPosV1-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3f9ba-dc89-4c32-a125-1fa85cd4132d",
   "metadata": {},
   "source": [
    "Ok, we're now done with processing the position data! We just have to do some table manipulations to make sure everything ends up in the same format and same location.<br>\n",
    "To summarize, we brought in a pretrained DLC project, used that model to run pose estimation on a new behavioral video, smoothed and interpolated the result, formed a cohort of bodyparts, and determined the centroid and orientation of this cohort. **_Whew!_**<br>\n",
    "Now let's populate `DLCPosV1` with our centroid and orientation entries from above.<br>----<br>\n",
    "To begin, we'll make a key that combines the cohort names we used for the orientation and centroid as well as the params names for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a166dd6-3863-4349-97ac-19d7d6a841b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = list(sgp.DLCPosV1.fetch().dtype.fields.keys())\n",
    "dlc_key = {key: val for key, val in centroid_key.items() if key in fields}\n",
    "dlc_key[\"dlc_si_cohort_centroid\"] = centroid_key[\"dlc_si_cohort_selection_name\"]\n",
    "dlc_key[\"dlc_si_cohort_orientation\"] = orient_key[\n",
    "    \"dlc_si_cohort_selection_name\"\n",
    "]\n",
    "dlc_key[\"dlc_orientation_params_name\"] = orient_key[\n",
    "    \"dlc_orientation_params_name\"\n",
    "]\n",
    "print(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e4c5e-7c32-46b0-a138-80064a212fbe",
   "metadata": {},
   "source": [
    "Now we can insert into `DLCPosSelection` and populate `DLCPos` with our `dlc_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7badff-0ad7-48cf-aef6-a4f55df8ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosSelection().insert1(dlc_key, skip_duplicates=True)\n",
    "sgp.DLCPosV1().populate(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f1cff-2ead-4489-8a10-9fa7a5d33292",
   "metadata": {},
   "source": [
    "We can also make sure that all of our data made it through by fetching the dataframe attached to this entry.<br>We should expect 8 columns:\n",
    ">time<br>video_frame_ind<br>position_x<br>position_y<br>orientation<br>velocity_x<br>velocity_y<br>speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853db96b-1cd4-4ff6-91ea-aca7f7d3851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCPosV1() & dlc_key).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8623a8-1725-4e02-b1a2-d2f993988102",
   "metadata": {},
   "source": [
    "And even more, we can fetch the `pose_eval_result` that is calculated during this step. This field contains the percentage of frames that each bodypart was below the likelihood threshold of 0.95 as a means of assessing the quality of the pose estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f06244-9d59-44d4-bcbb-062809b3ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCPosV1() & dlc_key).fetch1(\"pose_eval_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2303147-3657-479c-8f72-b3fc6905a596",
   "metadata": {},
   "source": [
    "#### [DLCPosVideo](#TableOfContents) <a id='DLCPosVideo1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b081d-f619-4c38-ba48-6ae1c0c5ff2b",
   "metadata": {},
   "source": [
    "Here we can create a video with the centroid and orientation overlaid on the animal's behavioral video. This will also plot the likelihood of each bodypart used in the cohort. This is completely optional, but a good idea to make sure everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a725c08-a616-43a0-8925-4a82bf872ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosVideoParams.insert_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2f782-ba45-487a-8e8f-e80dd33d9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"percent_frames\": 0.05,\n",
    "    \"incl_likelihood\": True,\n",
    "}\n",
    "sgp.DLCPosVideoParams.insert1(\n",
    "    {\"dlc_pos_video_params_name\": \"five_percent\", \"params\": params},\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758e2fc-13e6-46cb-9a93-ae1b4c1f4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosVideoSelection.insert1(\n",
    "    {**dlc_key, \"dlc_pos_video_params_name\": \"five_percent\"},\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887c0a5-77c8-421e-935e-0692f3f1fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosVideo().populate(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68bba8-9871-40ac-84c9-51ac0e76d44e",
   "metadata": {},
   "source": [
    "#### [PositionOutput](#TableOfContents) <a id='PositionOutput1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25325173-bbaf-4b85-aef6-201384d9933b",
   "metadata": {},
   "source": [
    "`PositionOutput` is the final table of the position pipeline and is automatically populated when we populate `DLCPosV1`! Let's make sure that our entry made it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec40c9-78d8-4edd-8158-be91fb15af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.PositionOutput.merge_get_part(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414d9e0-e495-42ef-a8b0-1c7d53aed02e",
   "metadata": {},
   "source": [
    "`PositionOutput` also has a part table, similar to the `DLCModelSource` table above. Let's check that out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50760123-7f09-4a94-a1f7-41a037914fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PositionOutput.DLCPosV1() & dlc_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96daaa9-5e70-4a2c-b0a4-c2849e3a1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_ids = PositionOutput.merge_get_part(dlc_key).fetch(\"merge_id\")\n",
    "(PositionOutput & {\"merge_id\": merge_ids[0]}).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c7a4e-0bbc-4101-baf2-e84f1f5739d5",
   "metadata": {},
   "source": [
    "#### [PositionVideo](#TableOfContents)<a id='PositionVideo1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e6602-8e80-47fa-be78-4ae120d52e41",
   "metadata": {},
   "source": [
    "Bonus points if you made it this far... We can use the `PositionVideo` table to create a video that overlays just the centroid and orientation (regardless of upstream source) on the behavioral video. This table uses the parameter `plot` to determine whether to plot the entry deriving from the DLC arm or from the Trodes arm of the position pipeline. This parameter also accepts 'all', which will plot both (if they exist) in order to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a782ce-0a14-4725-887f-ae6f341635f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.PositionVideoSelection().insert1(\n",
    "    {\n",
    "        \"nwb_file_name\": \"J1620210604_.nwb\",\n",
    "        \"interval_list_name\": \"pos 13 valid times\",\n",
    "        \"trodes_position_id\": 0,\n",
    "        \"dlc_position_id\": 1,\n",
    "        \"plot\": \"DLC\",\n",
    "        \"output_dir\": \"/home/dgramling/Src/\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32993e7-5b32-46f9-a2f9-9634aef785f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.PositionVideo.populate({\"plot\": \"DLC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be097052-3789-4d55-aca1-e44d426c39b4",
   "metadata": {},
   "source": [
    "### _CONGRATULATIONS!!_\n",
    "Please treat yourself to a nice tea break :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c90a2",
   "metadata": {},
   "source": [
    "### [Return To Table of Contents](#TableOfContents)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spyglass-position3] *",
   "language": "python",
   "name": "conda-env-spyglass-position3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
