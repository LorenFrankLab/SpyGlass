{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NWB-Datajoint tutorial 1\n",
    "\n",
    "**Note: make a copy of this notebook and run the copy to avoid git conflicts in the future**\n",
    "\n",
    "This is the first in a multi-part tutorial on the NWB-Datajoint pipeline used in Loren Frank's lab, UCSF. It demonstrates how to run spike sorting within the pipeline.\n",
    "\n",
    "If you have not done [tutorial 0](0_intro.ipynb) yet, make sure to do so before proceeding.\n",
    "\n",
    "Let's start by importing the `nwb_datajoint` package, along with a few others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datajoint as dj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import nwb_datajoint as nd\n",
    "\n",
    "# ignore datajoint+jupyter async warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=ResourceWarning)\n",
    "os.environ['NWB_DATAJOINT_TEMP_DIR']=\"/stelmo/nwb/tmp\"\n",
    "os.environ['KACHERY_STORAGE_DIR']=\"/stelmo/nwb/kachery-storage\"\n",
    "os.environ['FIGURL_CHANNEL']=\"franklab2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tables so that we can call them easily\n",
    "from nwb_datajoint.common import (RawPosition, HeadDir, Speed, LinPos, StateScriptFile, VideoFile,\n",
    "                                  IntervalPositionInfo, IntervalLinearizedPosition,\n",
    "                                  DataAcquisitionDevice, CameraDevice, Probe,\n",
    "                                  DIOEvents,\n",
    "                                  ElectrodeGroup, Electrode, Raw, SampleCount,\n",
    "                                  LFPSelection, LFP, LFPBandSelection, LFPBand,\n",
    "                                  SortGroup, SpikeSortingFilterParameters, SpikeSortingArtifactDetectionParameters,\n",
    "                                  SpikeSortingRecordingSelection, SpikeSortingRecording, \n",
    "                                  SpikeSortingWorkspace, \n",
    "                                  SpikeSorter, SpikeSorterParameters, SortingID,\n",
    "                                  SpikeSortingSelection, SpikeSorting, \n",
    "                                  SpikeSortingMetricParameters,\n",
    "                                  ModifySortingParameters, ModifySortingSelection, ModifySorting, \n",
    "                                  AutomaticCurationParameters, AutomaticCurationSelection,\n",
    "                                  AutomaticCuration,\n",
    "                                  CuratedSpikeSortingSelection, CuratedSpikeSorting,\n",
    "                                  UnitInclusionParameters,\n",
    "                                  FirFilter,\n",
    "                                  IntervalList, SortInterval,\n",
    "                                  Lab, LabMember, LabTeam, Institution,\n",
    "                                  BrainRegion,\n",
    "                                  SensorData,\n",
    "                                  Session, ExperimenterList,\n",
    "                                  Subject,\n",
    "                                  Task, TaskEpoch,\n",
    "                                  Nwbfile, AnalysisNwbfile, \n",
    "                                  KacheryChannel, NwbfileKacherySelection, NwbfileKachery,\n",
    "                                  AnalysisNwbfileKacherySelection, AnalysisNwbfileKachery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poskey = {'nwb_file_name': 'chimi20200216_new_.nwb', 'position_info_param_name':'default_decoding'}\n",
    "#IntervalPositionInfo. \n",
    "#IntervalLinearizedPosition \n",
    "lposkey= {'position_info_param_name': 'default',  'nwb_file_name': 'chimi20200216_new_.nwb', 'interval_list_name': 'pos 1 valid times',  'track_graph_name': '6 arm', 'linearization_param_name': 'default'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipi = (IntervalPositionInfo & poskey).fetch1()\n",
    "AnalysisNwbfileKacherySelection().insert1({'channel_name':'franklab2', 'analysis_file_name': ipi['analysis_file_name']}, skip_duplicates=True)\n",
    "AnalysisNwbfileKachery.populate()\n",
    "AnalysisNwbfileKachery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp = (IntervalLinearizedPosition & lposkey).fetch1()\n",
    "AnalysisNwbfileKacherySelection().insert1({'channel_name':'franklab2', 'analysis_file_name': ilp['analysis_file_name']}, skip_duplicates=True)\n",
    "ilp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### nwb_file_name = 'despereaux20191125_.nwb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingRecording & {'nwb_file_name':nwb_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {'nwb_file_name': 'chimi20200216_new_.nwb', 'position_info_param_name':'default_decoding'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {'nwb_file_name':nwb_file_name}\n",
    "(SpikeSortingRecording & key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = {'nwb_file_name':  nwb_file_name}\n",
    "SpikeSortingWorkspace().url(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_datajoint.decoding import UnitMarkParameters, UnitMarks, MarkParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnitMarks.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the lab members and team information for this sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to set sort group\n",
    "#SortGroup().set_group_by_electrode_group(nwb_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SortGroup.SortGroupElectrode & {'nwb_file_name': nwb_file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define sort interval\n",
    "Next, we make a decision about the time interval for our spike sorting. Let's re-examine `IntervalList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IntervalList & {'nwb_file_name' : nwb_file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, let's choose the first 600 seconds of the first run interval (`02_r1`) as our sort interval. To do so, we first fetch `valid_times` of this interval, define our new sort interval, and add this to the `SortInterval` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_list_name = '02_r1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_list = (IntervalList & {'nwb_file_name' : nwb_file_name,\n",
    "                            'interval_list_name' : interval_list_name}).fetch1('valid_times')\n",
    "print(interval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_interval = interval_list[0]\n",
    "sort_interval_name = interval_list_name\n",
    "sort_interval = np.copy(interval_list[0]) \n",
    "sort_interval[1] = sort_interval[0]+300\n",
    "sort_interval_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out SortInterval\n",
    "(SortInterval & {'nwb_file_name' : nwb_file_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the required attributes.\n",
    "# This time, the entries take the form of a dictionary.\n",
    "#SortInterval.insert1({'nwb_file_name' : nwb_file_name,\n",
    "#                      'sort_interval_name' : sort_interval_name,\n",
    "#                      'sort_interval' : sort_interval}, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See results\n",
    "SortInterval & {'nwb_file_name' : nwb_file_name, 'sort_interval_name': sort_interval_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the filtering parameters. Here we insert the default parameters and a new set of filtering parameters for hippocampal data\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingFilterParameters().insert_default()\n",
    "filter_param_dict = SpikeSortingFilterParameters.fetch('filter_parameter_dict')\n",
    "filter_param_dict = filter_param_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_param_dict['frequency_min'] = 600\n",
    "SpikeSortingFilterParameters().insert1({'filter_parameter_set_name': 'franklab_default_hippocampus', \n",
    "                                       'filter_parameter_dict' : filter_param_dict}, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we set up the SpikeSortingArtifactParameters which can allow us to remove artifacts from the data\n",
    "For the moment we just set up a \"none\" parameter set which will do nothing when used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingArtifactDetectionParameters().insert_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the recording parameters so we can get the recording extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_group_id = 2 # use sort group 2\n",
    "sort_interval_name = 'test'\n",
    "filter_param_name = 'franklab_default_hippocampus'\n",
    "artifact_param_name = 'none'\n",
    "interval_list = '02_r1'\n",
    "lab_team = 'Loren Frank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the params\n",
    "key = dict()\n",
    "key['nwb_file_name'] = nwb_file_name\n",
    "key['sort_group_id'] = sort_group_id\n",
    "key['filter_parameter_set_name'] = filter_param_name\n",
    "key['sort_interval_name'] = sort_interval_name\n",
    "key['artifact_parameter_name'] = artifact_param_name\n",
    "key['interval_list_name'] = interval_list\n",
    "key['team_name'] = 'Loren Frank'\n",
    "\n",
    "ssr_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingRecordingSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingRecordingSelection.insert1(key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingRecording.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to populate the SpikeSortingWorkspace table to make this recording available via kachery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SpikeSortingWorkspace.populate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, we will be using `mountainsort4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpikeSortingWorkspace().url(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SpikeSorter().insert_from_spikeinterface()\n",
    "SpikeSorterParameters().insert_from_spikeinterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_name='mountainsort4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the default params\n",
    "ms4_default_params = (SpikeSorterParameters & {'sorter_name' : sorter_name,\n",
    "                                               'spikesorter_parameter_set_name' : 'default'}).fetch1()\n",
    "print(ms4_default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the default params\n",
    "param_dict = ms4_default_params['parameter_dict']\n",
    "# Detect upward downward going spikes\n",
    "param_dict['detect_sign'] = -1 \n",
    "#We will sort electrodes together that are within 100 microns of each other\n",
    "param_dict['adjacency_radius'] = 100\n",
    "param_dict['curation'] = False\n",
    "# Turn filter off since we will filter it prior to starting sort\n",
    "param_dict['filter'] = False\n",
    "param_dict['freq_min'] = 0\n",
    "param_dict['freq_max'] = 0\n",
    "# Turn whiten off since we will whiten it prior to starting sort\n",
    "param_dict['whiten'] = False\n",
    "# set num_workers to be the same number as the number of electrodes\n",
    "param_dict['num_workers'] = 4\n",
    "param_dict['verbose'] = True\n",
    "# set clip size as number of samples for 1.33 millisecond\n",
    "param_dict['clip_size'] = np.int(1.33e-3 * (Raw & {'nwb_file_name' : nwb_file_name}).fetch1('sampling_rate'))\n",
    "param_dict['noise_overlap_threshold'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give a unique name here\n",
    "parameter_set_name = 'franklab_tetrode_hippocampus_30KHz'\n",
    "SpikeSorterParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert\n",
    "SpikeSorterParameters.insert1({'sorter_name': sorter_name,\n",
    "                               'spikesorter_parameter_set_name': parameter_set_name,\n",
    "                               'parameter_dict': param_dict}, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that insert was successful\n",
    "#p = (SpikeSorterParameters & {'sorter_name': sorter_name, 'parameter_set_name': parameter_set_name}).fetch1()\n",
    "p = (SpikeSorterParameters & {'sorter_name': sorter_name}).fetch()\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing everything together\n",
    "\n",
    "We now collect all the decisions we made up to here and put it into `SpikeSortingSelection` table (note: this is different from spike sor*ter* parameters defined above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (SpikeSortingWorkspace & ssr_key).fetch1(\"KEY\")\n",
    "key['sorter_name'] = sorter_name\n",
    "key['spikesorter_parameter_set_name'] = 'franklab_tetrode_hippocampus_30KHz'\n",
    "ss_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert\n",
    "SpikeSortingSelection.insert1(key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(SpikeSortingParameters & {'nwb_file_name' : nwb_file_name, 'sort_interval_name' : sort_interval_name}).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inspect\n",
    "(SpikeSortingSelection & {'nwb_file_name' : nwb_file_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running spike sorting\n",
    "Now we can run spike sorting. As we said it's nothing more than populating another table (`SpikeSorting`) from the entries of `SpikeSortingParameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify entry (otherwise runs everything in SpikeSortingParameters)\n",
    "# `proj` gives you primary key\"\n",
    "SpikeSorting.populate([(SpikeSortingSelection & {'nwb_file_name' : nwb_file_name, 'sort_interval_name' : sort_interval_name}).proj()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpikeSortingWorkspace().url(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define quality metric parameters\n",
    "\n",
    "We're almost done. There are more parameters related to how to compute the quality metrics for curation. We just use the default options here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingMetricParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = SpikeSortingMetricParameters().get_metric_dict()\n",
    "metric_param_dict = SpikeSortingMetricParameters().get_metric_parameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in metric_dict:\n",
    "    print(f\"'{k}': {metric_dict[k]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_dict['noise_overlap'] = True\n",
    "metric_dict['firing_rate'] = True\n",
    "metric_dict['num_spikes'] = True\n",
    "for k in metric_dict:\n",
    "    print(f\"'{k}': {metric_dict[k]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_metrics_list_name = 'franklab_cluster_metrics_09-19-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#(SpikeSortingMetricParameters & {'cluster_metrics_list_name' : cluster_metrics_list_name}).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the cluster metrics to the table if they are not there already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SpikeSortingMetricParameters.insert1({'cluster_metrics_list_name' : cluster_metrics_list_name,\n",
    "                            'metric_dict' : metric_dict, \n",
    "                            'metric_parameter_dict' : metric_param_dict}, skip_duplicates=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the default Automatic curation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = AutomaticCurationParameters().get_default_parameters()\n",
    "AutomaticCurationParameters().insert1({'automatic_curation_parameter_set_name':'none', \n",
    "                                      'automatic_curation_parameter_dict': param}, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add an entry to select those parameters for automatic curation of this recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first get the sorting ID\n",
    "acs_key = (SpikeSortingRecording & ssr_key).fetch1('KEY')\n",
    "acs_key['sorting_id'] = (SpikeSorting & ss_key).fetch1('sorting_id')\n",
    "acs_key['automatic_curation_parameter_set_name'] = 'none'\n",
    "acs_key['cluster_metrics_list_name'] = cluster_metrics_list_name\n",
    "AutomaticCurationSelection.insert1(acs_key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we populate the Autocuration table, which in this case just computes the metrics and does not add labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutomaticCuration.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutomaticCuration.populate(acs_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now curate the recording using the figurl interface. To do so, we get the figurl link for this recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSortingWorkspace().url(ssr_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're done with manual curation, you can add the units (with an optional new set of metrics) to the final CuratedSortingTable which includes only accepted units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css_key = (AutomaticCuration & acs_key).fetch1('KEY')\n",
    "css_key['sorting_id']\n",
    "css_key['final_cluster_metrics_list_name'] = cluster_metrics_list_name\n",
    "CuratedSpikeSortingSelection.insert1(css_key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CuratedSpikeSorting.populate(css_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CuratedSpikeSorting.Unit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_groups = (SortGroup & {'nwb_file_name' : nwb_file_name}).fetch('sort_group_id')\n",
    "sort_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpikeSorting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.ERD(SpikeSorting)+5-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.ERD(ModifySorting)+3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = CuratedSpikeSorting().Unit().fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units['noise_overlap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwb_datajoint",
   "language": "python",
   "name": "nwb_datajoint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
