{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook assumes that you've imported one or more NWB files into DataJoint \n",
    "## It allows you to run spikesorters on those data using the SpikeInterface package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all of the relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pynwb\n",
    "import os\n",
    "\n",
    "# CHANGE ME TO THE BASE DIRECTORY FOR DATA STORAGE ON YOUR SYSTEM\n",
    "# data_dir = Path('/Users/loren/data/nwb_builder_test_data') \n",
    "data_dir = Path('/mnt/c/Users/Ryan/Documents/NWB_Data/Frank Lab Data/')\n",
    "\n",
    "raw_dir = data_dir / 'raw'\n",
    "analysis_dir = data_dir / 'analysis'\n",
    "\n",
    "os.environ['NWB_DATAJOINT_BASE_DIR'] = str(data_dir)\n",
    "os.environ['KACHERY_STORAGE_DIR'] = str(data_dir / 'kachery-storage')\n",
    "os.environ['SPIKE_SORTING_STORAGE_DIR'] = str(data_dir / 'spikesorting')\n",
    "os.environ['DJ_SUPPORT_FILEPATH_MANAGEMENT'] = 'TRUE'\n",
    "\n",
    "# DataJoint and DataJoint schema\n",
    "import datajoint as dj\n",
    "dj.config['database.host'] = 'localhost'\n",
    "dj.config['database.user'] = 'root'\n",
    "dj.config['database.password'] = 'tutorial'\n",
    "dj.config['stores'] = {\n",
    "  'raw': {\n",
    "    'protocol': 'file',\n",
    "    'location': str(raw_dir),\n",
    "    'stage' : str(raw_dir)\n",
    "  },\n",
    "  'analysis': {\n",
    "    'protocol': 'file',\n",
    "    'location': str(analysis_dir),\n",
    "    'stage': str(analysis_dir)\n",
    "  }\n",
    "}\n",
    "\n",
    "import nwb_datajoint as nd\n",
    "from ndx_franklab_novela import Probe\n",
    "\n",
    "import spiketoolkit as st\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the nwb file name and the name of the probe file to create from DataJoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nwb_file_name = (nd.common.Session() & {'session_id': 'beans_01'}).fetch1('nwb_file_name')\n",
    "# nwb_file_name = 'beans20190718_.nwb'\n",
    "nwb_file_name = 'beans20190718-trim_.nwb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the sort grouping by shank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SortGroup().set_group_by_shank(nwb_file_name)\n",
    "nd.common.SortGroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Display all of the electrodes with their sort groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SortGroup.SortGroupElectrode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the spike sorter and parameter lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SpikeSorter().insert_from_spikeinterface()\n",
    "nd.common.SpikeSorterParameters().insert_from_spikeinterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SpikeSorterParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a 'franklab_mountainsort' parameter set\n",
    "#### Note that we're doing the filtering using spikeinterface, so we set filter to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (nd.common.SpikeSorterParameters() & {'sorter_name': 'mountainsort4', 'parameter_set_name' : 'default'}).fetch1()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (nd.common.SpikeSorterParameters() & {'sorter_name': 'mountainsort4', 'parameter_set_name' : 'default'}).fetch1()\n",
    "param = p['parameter_dict']\n",
    "param['adjacency_radius'] = 100\n",
    "param['curation'] = False\n",
    "param['filter'] = False\n",
    "param['num_workers'] = 7\n",
    "param['verbose'] = True\n",
    "param['clip_size'] = 30\n",
    "param['noise_overlap_threshold'] = 0\n",
    "\n",
    "nd.common.SpikeSorterParameters().insert1({'sorter_name': 'mountainsort4', \n",
    "                                           'parameter_set_name': 'franklab_mountainsort_20KHz', \n",
    "                                           'parameter_dict' : param}, \n",
    "                                          skip_duplicates='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the new parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (nd.common.SpikeSorterParameters() & {'sorter_name': 'mountainsort4', 'parameter_set_name': 'franklab_mountainsort_20KHz'}).fetch1()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = p['parameter_dict']\n",
    "param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a set of spike sorting parameters for sorting group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 10 second test intervals for debugging\n",
    "s1 = (nd.common.IntervalList() & {'interval_list_name': '01_s1'}).fetch1('valid_times')\n",
    "print(s1)\n",
    "\n",
    "a = np.asarray([s1[0][0], s1[0][0]+240])\n",
    "print(a)\n",
    "\n",
    "nd.common.SortInterval().insert1({'nwb_file_name': nwb_file_name, 'sort_interval_name': 'test', 'sort_interval': a}, replace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sorting waveform parameters table\n",
    "waveform_param_dict = st.postprocessing.get_waveforms_params()\n",
    "waveform_param_dict['grouping_property'] = 'group'\n",
    "# set the window to half of the clip size before and half after\n",
    "waveform_param_dict['ms_before'] = .75\n",
    "waveform_param_dict['ms_after'] = .75\n",
    "waveform_param_dict['dtype'] = 'i2'\n",
    "waveform_param_dict['verbose'] = False\n",
    "waveform_param_dict['max_spikes_per_unit'] = 1000\n",
    "nd.common.SpikeSortingWaveformParameters.insert1({'waveform_parameters_name': 'franklab default', \n",
    "                                                  'waveform_parameter_dict': waveform_param_dict}, \n",
    "                                                 replace='True')\n",
    "nd.common.SpikeSortingWaveformParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a list of metrics to be computed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = nd.common.SpikeSortingMetrics().get_metric_dict()\n",
    "metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a set of metrics to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict['num_spikes'] = True\n",
    "metric_dict['firing_rate'] = True\n",
    "metric_dict['isi_violation'] = True\n",
    "metric_dict['nn_hit_rate'] = True\n",
    "#metric_dict['noise overlap'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for computing the metrics. \\\n",
    "All of the parameters in the schema have default values, so we only need to specify the ones that we want to change. \\\n",
    "See spiketoolkit.validation documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_waveforms=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SpikeSortingMetrics().insert1({'cluster_metrics_list_name': 'll_fl_probe_metrics', \n",
    "                                         'n_cluster_waveforms' : n_cluster_waveforms,\n",
    "                                         'metrics_dict' : metric_dict}, \n",
    "                                        skip_duplicates='True')\n",
    "nd.common.SpikeSortingMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_group_id = 1\n",
    "key = dict()\n",
    "key['nwb_file_name'] = nwb_file_name\n",
    "key['sort_group_id'] = sort_group_id\n",
    "key['sorter_name'] = 'mountainsort4'\n",
    "key['parameter_set_name'] = 'franklab_mountainsort_20KHz'\n",
    "key['waveform_parameters_name'] = 'franklab default'\n",
    "key['interval_list_name'] = '01_s1'\n",
    "key['sort_interval_name'] = 'test'\n",
    "key['cluster_metrics_list_name'] = 'll_fl_probe_metrics'\n",
    "nd.common.SpikeSortingParameters().insert1(key, skip_duplicates='True')\n",
    "nd.common.SpikeSortingParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the sort - this can take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SpikeSorting().populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Example: Retrieve the spike trains:\n",
    "Note that these spikes are all noise; this is for demonstration purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = (nd.common.SpikeSorting & {'nwb_file_name' : nwb_file_name, 'sort_group_id' : sort_group_id}).fetch()\n",
    "key = {'nwb_file_name' : nwb_file_name, 'sort_group_id' : sort_group_id}\n",
    "units = (nd.common.SpikeSorting & key).fetch_nwb()[0]['units'].to_dataframe()\n",
    "units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything below here is for deleting schema or testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SpikeSorting.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.AnalysisNwbfile().delete()\n",
    "nd.common.AnalysisNwbfile().cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.AnalysisNwbfile().drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.SpikeSorting().delete()\n",
    "nd.common.AnalysisNwbfile().cleanup(delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_interval = (nd.common.SortIntervalList() & {'sort_interval_list_name' : 'test'}).fetch1('sort_intervals')[0]\n",
    "\n",
    "key = nd.common.SpikeSorting().fetch('KEY')[0]\n",
    "\n",
    "recording = nd.common.SpikeSorting().get_recording_extractor(key, sort_interval)[0]\n",
    "sorting = nd.common.SpikeSorting().get_sorting_extractor(key, sort_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the timestamps and select 1000 random times\n",
    "raw_obj = (nd.common.Raw() & {'nwb_file_name' : nwb_file_name}).fetch_nwb()[0]['raw']\n",
    "ts = np.asarray(raw_obj.timestamps)\n",
    "ts_sort_ind = np.where(np.logical_and((ts > sort_interval[0]), (ts < sort_interval[1])))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.common.Nwbfile().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.validation.get_quality_metrics_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nwb_datajoint] *",
   "language": "python",
   "name": "conda-env-nwb_datajoint-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
